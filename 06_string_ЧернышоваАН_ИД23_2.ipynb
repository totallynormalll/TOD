{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xADpR0DRnVe"
      },
      "source": [
        "# Работа со строковыми значениями"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn9p2RRKRnVk"
      },
      "source": [
        "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
        "\n",
        "Материалы:\n",
        "* Макрушин С.В. Лекция \"Работа со строковыми значениям\"\n",
        "* https://pyformat.info/\n",
        "* https://docs.python.org/3/library/re.html\n",
        "    * https://docs.python.org/3/library/re.html#flags\n",
        "    * https://docs.python.org/3/library/re.html#functions\n",
        "* https://pythonru.com/primery/primery-primeneniya-regulyarnyh-vyrazheniy-v-python\n",
        "* https://kanoki.org/2019/11/12/how-to-use-regex-in-pandas/\n",
        "* https://realpython.com/nltk-nlp-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBpfzxfURnVm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import regex as re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HmsXUwERnVn"
      },
      "source": [
        "## Лабораторная работа 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIDeaTc1RnVo"
      },
      "source": [
        "### Форматирование строк"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfToHLw3RnVo"
      },
      "source": [
        "1\\. Загрузите данные из файла `recipes_sample.csv` (__ЛР2__) в виде `pd.DataFrame` `recipes` При помощи форматирования строк выведите информацию об id рецепта и времени выполнения 5 случайных рецептов в виде таблицы следующего вида:\n",
        "\n",
        "    \n",
        "    |      id      |  minutes  |\n",
        "    |--------------------------|\n",
        "    |    61178     |    65     |\n",
        "    |    202352    |    80     |\n",
        "    |    364322    |    150    |\n",
        "    |    26177     |    20     |\n",
        "    |    224785    |    35     |\n",
        "    \n",
        "Обратите внимание, что ширина столбцов заранее неизвестна и должна рассчитываться динамически, в зависимости от тех данных, которые были выбраны."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "696VZfUbRnVo",
        "outputId": "6ce72b21-1406-4062-b419-335e162b063e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>id</th>\n",
              "      <th>minutes</th>\n",
              "      <th>contributor_id</th>\n",
              "      <th>submitted</th>\n",
              "      <th>n_steps</th>\n",
              "      <th>description</th>\n",
              "      <th>n_ingredients</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>george s at the cove  black bean soup</td>\n",
              "      <td>44123</td>\n",
              "      <td>90</td>\n",
              "      <td>35193</td>\n",
              "      <td>2002-10-25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>an original recipe created by chef scott meska...</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>healthy for them  yogurt popsicles</td>\n",
              "      <td>67664</td>\n",
              "      <td>10</td>\n",
              "      <td>91970</td>\n",
              "      <td>2003-07-26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>my children and their friends ask for my homem...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i can t believe it s spinach</td>\n",
              "      <td>38798</td>\n",
              "      <td>30</td>\n",
              "      <td>1533</td>\n",
              "      <td>2002-08-29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>these were so go, it surprised even me.</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>italian  gut busters</td>\n",
              "      <td>35173</td>\n",
              "      <td>45</td>\n",
              "      <td>22724</td>\n",
              "      <td>2002-07-27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>my sister-in-law made these for us at a family...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>love is in the air  beef fondue   sauces</td>\n",
              "      <td>84797</td>\n",
              "      <td>25</td>\n",
              "      <td>4470</td>\n",
              "      <td>2004-02-23</td>\n",
              "      <td>4.0</td>\n",
              "      <td>i think a fondue is a very romantic casual din...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>zurie s holey rustic olive and cheddar bread</td>\n",
              "      <td>267661</td>\n",
              "      <td>80</td>\n",
              "      <td>200862</td>\n",
              "      <td>2007-11-25</td>\n",
              "      <td>16.0</td>\n",
              "      <td>this is based on a french recipe but i changed...</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>zwetschgenkuchen  bavarian plum cake</td>\n",
              "      <td>386977</td>\n",
              "      <td>240</td>\n",
              "      <td>177443</td>\n",
              "      <td>2009-08-24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>this is a traditional fresh plum cake, thought...</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>zwiebelkuchen   southwest german onion cake</td>\n",
              "      <td>103312</td>\n",
              "      <td>75</td>\n",
              "      <td>161745</td>\n",
              "      <td>2004-11-03</td>\n",
              "      <td>NaN</td>\n",
              "      <td>this is a traditional late summer early fall s...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>zydeco soup</td>\n",
              "      <td>486161</td>\n",
              "      <td>60</td>\n",
              "      <td>227978</td>\n",
              "      <td>2012-08-29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>this is a delicious soup that i originally fou...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>cookies by design   cookies on a stick</td>\n",
              "      <td>298512</td>\n",
              "      <td>29</td>\n",
              "      <td>506822</td>\n",
              "      <td>2008-04-15</td>\n",
              "      <td>9.0</td>\n",
              "      <td>i've heard of the 'cookies by design' company,...</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               name      id  minutes  \\\n",
              "0             george s at the cove  black bean soup   44123       90   \n",
              "1                healthy for them  yogurt popsicles   67664       10   \n",
              "2                      i can t believe it s spinach   38798       30   \n",
              "3                              italian  gut busters   35173       45   \n",
              "4          love is in the air  beef fondue   sauces   84797       25   \n",
              "...                                             ...     ...      ...   \n",
              "29995  zurie s holey rustic olive and cheddar bread  267661       80   \n",
              "29996          zwetschgenkuchen  bavarian plum cake  386977      240   \n",
              "29997   zwiebelkuchen   southwest german onion cake  103312       75   \n",
              "29998                                   zydeco soup  486161       60   \n",
              "29999        cookies by design   cookies on a stick  298512       29   \n",
              "\n",
              "       contributor_id   submitted  n_steps  \\\n",
              "0               35193  2002-10-25      NaN   \n",
              "1               91970  2003-07-26      NaN   \n",
              "2                1533  2002-08-29      NaN   \n",
              "3               22724  2002-07-27      NaN   \n",
              "4                4470  2004-02-23      4.0   \n",
              "...               ...         ...      ...   \n",
              "29995          200862  2007-11-25     16.0   \n",
              "29996          177443  2009-08-24      NaN   \n",
              "29997          161745  2004-11-03      NaN   \n",
              "29998          227978  2012-08-29      NaN   \n",
              "29999          506822  2008-04-15      9.0   \n",
              "\n",
              "                                             description  n_ingredients  \n",
              "0      an original recipe created by chef scott meska...           18.0  \n",
              "1      my children and their friends ask for my homem...            NaN  \n",
              "2                these were so go, it surprised even me.            8.0  \n",
              "3      my sister-in-law made these for us at a family...            NaN  \n",
              "4      i think a fondue is a very romantic casual din...            NaN  \n",
              "...                                                  ...            ...  \n",
              "29995  this is based on a french recipe but i changed...           10.0  \n",
              "29996  this is a traditional fresh plum cake, thought...           11.0  \n",
              "29997  this is a traditional late summer early fall s...            NaN  \n",
              "29998  this is a delicious soup that i originally fou...            NaN  \n",
              "29999  i've heard of the 'cookies by design' company,...           10.0  \n",
              "\n",
              "[30000 rows x 8 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recipes = pd.read_csv('recipes_sample.csv')\n",
        "recipes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPSG12X0RnVq",
        "outputId": "a1dd66dd-f644-48c0-9970-bb4a6e5e84df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|  id  |minutes|\n",
            "-------------\n",
            "|277058|130|\n",
            "|65112 |40 |\n",
            "|100776| 5 |\n",
            "|55875 |15 |\n",
            "|138305|30 |\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "recipes = pd.read_csv('recipes_sample.csv')\n",
        "random_recipes = recipes.sample(5)\n",
        "\n",
        "# Calculate the maximum width for each column\n",
        "max_width_id = max(len(str(id)) for id in random_recipes['id'])\n",
        "max_width_minutes = max(len(str(minutes)) for minutes in random_recipes['minutes'])\n",
        "\n",
        "#создаем таблицу({}- задает ширину полученную )\n",
        "table = \"|{:^{}}|{:^{}}|\\n\".format('id', max_width_id, 'minutes', max_width_minutes)\n",
        "table += \"-\" * (max_width_id + max_width_minutes + 4) + \"\\n\"\n",
        "\n",
        "for index, row in random_recipes.iterrows():\n",
        "    table += \"|{:^{}}|{:^{}}|\\n\".format(row['id'], max_width_id, row['minutes'], max_width_minutes)\n",
        "\n",
        "print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2p_q4cBRnVr"
      },
      "source": [
        "2\\. Напишите функцию `show_info`, которая по данным о рецепте создает строку (в смысле объекта python) с описанием следующего вида:\n",
        "\n",
        "```\n",
        "\"Название Из Нескольких Слов\"\n",
        "\n",
        "1. Шаг 1\n",
        "2. Шаг 2\n",
        "----------\n",
        "Автор: contributor_id\n",
        "Среднее время приготовления: minutes минут\n",
        "```\n",
        "\n",
        "    \n",
        "Данные для создания строки получите из файлов `recipes_sample.csv` (__ЛР2__) и `steps_sample.xml` (__ЛР3__).\n",
        "Вызовите данную функцию для рецепта с id `170895` и выведите (через `print`) полученную строку на экран."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s1h3gVZRnVt",
        "outputId": "447e2820-690d-40a7-e1e4-b9f65932f0d1"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "show_info() missing 2 required positional arguments: 'contributor_id' and 'minutes'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m     info_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msteps_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m----------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mАвтор: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontributor_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mСреднее время приготовления: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminutes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m минут\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m info_str\n\u001b[1;32m---> 26\u001b[0m recipe_info \u001b[38;5;241m=\u001b[39m show_info( recipe_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m170895\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(recipe_info)\n",
            "\u001b[1;31mTypeError\u001b[0m: show_info() missing 2 required positional arguments: 'contributor_id' and 'minutes'"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "\n",
        "def show_info(contributor_id, minutes, recipe_id):\n",
        "    with open('recipes_sample.csv', newline='') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        recipe_data = next((row for row in reader if row['id'] == recipe_id), None)\n",
        "\n",
        "    if recipe_data is None:\n",
        "        return \"No recipe found with the given id.\"\n",
        "\n",
        "    name = recipe_data['name']\n",
        "    name = name.title()\n",
        "    name = ' '.join(word for word in name.split() if word)\n",
        "\n",
        "    steps_tree = ET.parse('steps_sample.xml')\n",
        "    steps_root = steps_tree.getroot()\n",
        "    steps_list = [step.text for step in steps_root.findall('.//step') if step.get('recipeId') == recipe_id]\n",
        "\n",
        "    steps_str = '\\n'.join([f'{index + 1}. {step}' for index, step in enumerate(steps_list)])\n",
        "    divider = '-' * len(name)\n",
        "\n",
        "    info_str = f\"{name}\\n\\n{steps_str}\\n\\n----------\\nАвтор: {contributor_id}\\nСреднее время приготовления: {minutes} минут\"\n",
        "    return info_str\n",
        "\n",
        "recipe_info = show_info( recipe_id=170895)\n",
        "print(recipe_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV-RKs8_RnVv"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "recipes_data = pd.read_csv('recipes_sample.csv')\n",
        "steps_data = ('steps_sample.xml')\n",
        "\n",
        "def show_info(recipe_id, recipes_data, steps_data):\n",
        "    recipe_info = recipes_data[recipes_data[\"id\"] == recipe_id]\n",
        "    steps_info = steps_data[steps_data[\"recipe_id\"] == recipe_id]\n",
        "\n",
        "    recipe_name = recipe_info[\"name\"].values[0]\n",
        "    contributor_id = recipe_info[\"contributor_id\"].values[0]\n",
        "    minutes = recipe_info[\"minutes\"].values[0]\n",
        "\n",
        "    steps_list = [f\"{i+1}. {step}\" for i, step in enumerate(steps_info[\"description\"])]\n",
        "\n",
        "    info_string = f'\"{recipe_name}\"\\n\\n' + '\\n'.join(steps_list) + '\\n----------\\n' + f'Автор: {contributor_id}\\n' + f'Среднее время приготовления: {minutes} минут'\n",
        "\n",
        "    return info_string\n",
        "recipe_id = 170895\n",
        "info = show_info(recipe_id, recipes_data, steps_data)\n",
        "print(info)  # Вывод полученной строки на экран\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbzU-LKBRnVv"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def show_info(recipes_id):\n",
        "    # Load recipes data from CSV file\n",
        "    with open('recipes_sample.csv', newline='') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        recipes = {row['id']: row for row in reader}\n",
        "\n",
        "    # Load steps data from XML file\n",
        "    tree = ET.parse('steps_sample.xml')\n",
        "    root = tree.getroot()\n",
        "    steps = {step.attrib['recipe_id']: [step.text for step in step.findall('step')] for step in root.findall('recipe')}\n",
        "\n",
        "    # Get recipe and steps data\n",
        "    recipe = recipes.get(recipe_id)\n",
        "    steps_data = steps.get(recipe_id)\n",
        "\n",
        "    if not recipe or not steps_data:\n",
        "        return f\"Recipe with id {recipe_id} not found.\"\n",
        "\n",
        "    # Create recipe description string\n",
        "    recipe_description = f\"\\n\\\"{recipe['title']}\\\"\\n\\n\"\n",
        "    for i, step in enumerate(steps_data, start=1):\n",
        "        recipe_description += f\"{i}. {step}\\n\"\n",
        "    recipe_description += \"----------\\n\"\n",
        "    recipe_description += f\"Автор: {recipe['contributor_id']}\\n\"\n",
        "    recipe_description += f\"Среднее время приготовления: {recipe['cooking_time']} минут\\n\"\n",
        "\n",
        "    return recipe_description\n",
        "\n",
        "# Call the function for recipe with id 170895 and print the result\n",
        "print(show_info(170895))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8oSppbeRnVw"
      },
      "outputs": [],
      "source": [
        "recipe_id = 170895\n",
        "info = show_info(recipe_id, recipes_data, steps_data)\n",
        "print(info)  # Вывод полученной строки на экран"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9e-NBMRRnVw"
      },
      "outputs": [],
      "source": [
        "assert (\n",
        "    show_info(\n",
        "        name=\"george s at the cove black bean soup\",\n",
        "        steps=[\n",
        "            \"clean the leeks and discard the dark green portions\",\n",
        "            \"cut the leeks lengthwise then into one-inch pieces\",\n",
        "            \"melt the butter in a medium skillet , med\",\n",
        "        ],\n",
        "        minutes=90,\n",
        "        author_id=35193,\n",
        "    )\n",
        "    == '\"George S At The Cove Black Bean Soup\"\\n\\n1. Clean the leeks and discard the dark green portions\\n2. Cut the leeks lengthwise then into one-inch pieces\\n3. Melt the butter in a medium skillet , med\\n----------\\nАвтор: 35193\\nСреднее время приготовления: 90 минут\\n'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfosrWabRnVw"
      },
      "source": [
        "## Работа с регулярными выражениями"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHPwiam5RnVx"
      },
      "source": [
        "3\\. Напишите регулярное выражение, которое ищет следующий паттерн в строке: число (1 цифра или более), затем пробел, затем слова: hour или hours или minute или minutes. Произведите поиск по данному регулярному выражению в каждом шаге рецепта с id 25082. Выведите на экран все непустые результаты, найденные по данному шаблону."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoNeFq8JRnVx",
        "outputId": "151fad95-488e-4826-dcd7-37ca37595c31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['20 minute']\n",
            "['10 minute']\n",
            "['2 hour']\n",
            "['10 minute']\n",
            "['20 minute', '30 minute']\n"
          ]
        }
      ],
      "source": [
        "tree = ET.parse(\"steps_sample.xml\")\n",
        "root = tree.getroot()\n",
        "\n",
        "recipe_id = 25082\n",
        "steps = []\n",
        "for recipe in root.findall('recipe'):\n",
        "    if recipe.find('id').text == str(recipe_id):\n",
        "        steps = [step.text.strip() for step in recipe.find('steps').findall('step')]\n",
        "\n",
        "# ?: - не захватывающая группа\n",
        "pattern = r'\\d+\\s+(?:hour|hours|minute|minutes)'\n",
        "for step in steps:\n",
        "    matches = re.findall(pattern, step)\n",
        "    if matches:\n",
        "        print(matches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CaYZWj3RnVx"
      },
      "source": [
        "4\\. Напишите регулярное выражение, которое ищет шаблон вида \"this..., but\" _в начале строки_ . Между словом \"this\" и частью \", but\" может находиться произвольное число букв, цифр, знаков подчеркивания и пробелов. Никаких других символов вместо многоточия быть не может. Пробел между запятой и словом \"but\" может присутствовать или отсутствовать.\n",
        "\n",
        "Используя строковые методы `pd.Series`, выясните, для каких рецептов данный шаблон содержится в тексте описания. Выведите на экран количество таких рецептов и 3 примера подходящих описаний (текст описания должен быть виден на экране полностью)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXXfvVcpRnVx",
        "outputId": "28880e0c-01ed-4f96-9e9c-477ccf1edcd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this is a great meal eaten the same day ,but\n",
            "this was adapted from a recipe i found on the net, but\n",
            "this is kind of similar to some of the other versions out there, but\n",
            "this is a moist, but\n",
            "this pie does not have very many ingredients in it, but\n",
            "this is very different, but\n",
            "this is really to simple to call a recipe,but\n",
            "this dressing is wonderful on baby greens salad, but\n",
            "this is a great recipe, but\n",
            "this casserole may be made with regular white rice, but\n",
            "this salad has quite a few ingredients, but\n",
            "this marinade is wonderful for any meat, but\n",
            "this recipe shows for pork, but\n",
            "this is considered peasant soup, but\n",
            "this recipe is posted by request, but\n",
            "this is a terribly sinful dish, but\n",
            "this is not only fantastic hot, but\n",
            "this is so gringo it is unreal, but\n",
            "this recipe is so good you will want to save it for company, but\n",
            "this cake is very rich, but\n",
            "this soup is served as a fancy appetizer in a shot glass with half a piece of candied bacon, but\n",
            "this is a rich creamy drink made of vodka, but\n",
            "this is traditionally a vegetarian dish, but\n",
            "this is a very simple recipe, but\n",
            "this is about as far from gourmet as you can get, but\n",
            "this sounds like a weird combination of ingredients, but\n",
            "this is a recipe that i make to serve to guests, but\n",
            "this recipe makes a lot, but\n",
            "this is a bit time consuming, but\n",
            "this tastes rich and looks like an expensive gourmet entree, but\n",
            "this dish is a wonderful weekday meal, but\n",
            "this is wonderful when peaches are fresh and in season, but\n",
            "this recipe is for 2 steaks or 3 very small steaks, but\n",
            "this classic chinese dish is so simple, but\n",
            "this is really nice inside my best ever chocolate cake, but\n",
            "this recipes takes a little playing around, but\n",
            "this is a concoction for salmon that i came up with when i wanted salmon, but\n",
            "this pie crust retains the flavor of an all butter crust, but\n",
            "this is not only fairly easy, but\n",
            "this recipe is not exactly crab rangoon,but\n",
            "this is sooooo simple, but\n",
            "this doctored up version of boxed mac and cheese is quick and easy, but\n",
            "this was born one night when i was trying a new recipe, but\n",
            "this not so healthy, but\n",
            "this sounds really good, but\n",
            "this recipe is insanely high in fiber and protein, but\n",
            "this is a nice simple way to prepare chicken in the crock pot, but\n",
            "this apple cake is super easy and quick to make, but\n",
            "this is almost too easy to be called a recipe, but\n",
            "this is from my pumpkin nuggets recipe, but\n",
            "this is a great fried turkey recipe, but\n",
            "this recipe is a work in process, but\n",
            "this tasted soooooo good, but\n",
            "this spread is delicious on crackers and toasts, but\n",
            "this is a somersize recipe, but\n",
            "this dish used to have a different name, but\n",
            "this makes a big batch, but\n",
            "this is pretty easy, but\n",
            "this recipe is very similar to other feta chicken recipes on recipezaar, but\n",
            "this chowder is great when you feel like soup, but\n",
            "this tastes like the  well known boursin cheese, but\n",
            "this was a long one to type, but\n",
            "this is for those of you who enjoy hot apple cider, but\n",
            "this recipe is not exactly like they have around here, but\n",
            "this is from a recent foodday section of the oregonian, but\n",
            "this is a great recipie, but\n",
            "this is a traditional indonesian recipe for fried chicken, but\n",
            "this is not a fancy beef gravy and i am not claiming it to be the best, but\n",
            "this is how i make broccoflower, but\n",
            "this is a great recipe to serve as an appetizer for two or three people, but\n",
            "this recipe is so simple i almost decided not to post it, but\n",
            "this is an ideal marinade for those who like spicy, but\n",
            "this is listed in bon appetit as a side accompaniament for cheesecake, but\n",
            "this actually takes a little effort to make, but\n",
            "this is a simple recipe, but\n",
            "this is absolutely delicious, but\n",
            "this is good with desserts, but\n",
            "this recipe sounds a little strange, but\n",
            "this is sooo good, but\n",
            "this is an easy cake, but\n",
            "this has a lot of ingredients, but\n",
            "this recipe might come across as more of a dressing than a salad, but\n",
            "this recipe is for one, but\n",
            "this dish is so easy to make, but\n",
            "this recipe is quick and easy, but\n",
            "this is such an easy, but\n",
            "this spanish dish is a lot like our sloppy joes, but\n",
            "this is so simple, but\n",
            "this cake is easier to make the the traditional recipe, but\n",
            "this is a wonderful sauce for any kind of venison, but\n",
            "this is posted by request, but\n",
            "this is a different, but\n",
            "this recipe is similar to others posted here, but\n",
            "this grilled chicken gets great flavor from the outdoor grill, but\n",
            "this recipe was originally meant for elementary students, but\n",
            "this is a great weeknight meal, but\n",
            "this is a copycat recipe, but\n",
            "this is a recipe that i clipped from a magazine years ago, but\n",
            "this is really great to have on hand when you have little time, but\n",
            "this recipe originally from a taste of home magazine, but\n",
            "this is not a low cal sauce, but\n",
            "this sauce is terrific with any seafood, but\n",
            "this is an unusual tart which can be baked all year round using elderflower cordial, but\n",
            "this rice not only looks beautiful, but\n",
            "this is also good made with jumbo lump crabmeat, but\n",
            "this sauce is more sweet than sour, but\n",
            "this is a very ellegant special dinner for two, but\n",
            "this is a simple, but\n",
            "this drink is rich, but\n",
            "this has a lot of ingredients in it, but\n",
            "this is a delicious traditional spanish dessert and is similar to cold custard, but\n",
            "this is wonderfully easy for those fall evenings when you want something tasty, but\n",
            "this recipe tastes very similar to the spicy tuna rolls found in japanese restaurants, but\n",
            "this is the original recipe, but\n",
            "this salad has the regular ingredients you would expect to find in a spinach salad, but\n",
            "this apple pie is loaded with apples, but\n",
            "this recipe is based off of a cooking light recipe, but\n",
            "this recipe is very simple, but\n",
            "this entrée packs a powerful flavor punch, but\n",
            "this uses frozen cheesesteak meat, but\n",
            "this is a nice side salad that i first had as a side at a thai restaurant, but\n",
            "this brownie batter comes from a mix, but\n",
            "this  healthy salad is not only easy to make, but\n",
            "this sounds so good, but\n",
            "this recipe is a little bit of work, but\n",
            "this only serves 2 as a side dish, but\n",
            "this is delicious anytime, but\n",
            "this is fabulous for a brunch, but\n",
            "this looks and smells like orange juice, but\n",
            "this is so simple to put together and tastes so good, but\n",
            "this is so good, but\n",
            "this simple salad pairs wonderfully with any meal, but\n",
            "this recipe is pretty close to bizzare, but\n",
            "this is a delicious soup that i originally found on the better homes and gardens website, but\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "recipes = pd.read_csv('recipes_sample.csv', header=0)\n",
        "pattern = r'^this([\\w\\d\\s]+),\\s?but'\n",
        "for desc in recipes['description']:\n",
        "    if isinstance(desc, str):\n",
        "        match = re.search(pattern, desc)\n",
        "        if match:\n",
        "            print(match.group())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g0PLrrxRnVy"
      },
      "source": [
        "5\\. В текстах шагов рецептов обыкновенные дроби имеют вид \"a / b\". Используя регулярные выражения, уберите в тексте шагов рецепта с id 72367 пробелы до и после символа дроби. Выведите на экран шаги этого рецепта после их изменения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rwi4CQ-bRnVy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "tree = ET.parse(\"steps_sample.xml\")\n",
        "root = tree.getroot()\n",
        "\n",
        "recipe_id = 72367\n",
        "steps = []\n",
        "for recipe in root.findall('recipe'):\n",
        "    if recipe.find('id').text == str(recipe_id):\n",
        "        steps = [step.text.strip() for step in recipe.find('steps').findall('step')]\n",
        "\n",
        "pattern = r'(\\d+)\\s?/\\s?(\\d+)'\n",
        "i = -1\n",
        "for step in steps:\n",
        "    i += 1\n",
        "    match = re.search(pattern, step)\n",
        "    if match:\n",
        "        new_s = step[:match.start() + 1] + match.group(1) + '/' + match.group(2) + step[match.end():]\n",
        "        steps[i] = new_s\n",
        "\n",
        "for step in steps:\n",
        "    print(step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UADZvCX0RnVy"
      },
      "source": [
        "### Сегментация текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PahcNKiBRnVy"
      },
      "source": [
        "6\\. Разбейте тексты шагов рецептов на слова при помощи пакета `nltk`. Посчитайте и выведите на экран кол-во уникальных слов среди всех рецептов. Словом называется любая последовательность алфавитных символов (для проверки можно воспользоваться `str.isalpha`). При подсчете количества уникальных слов не учитывайте регистр."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQDkLn5ORnVy",
        "outputId": "9a61d07a-6a41-4989-e31e-36fd3f415db8"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\kiril/nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m     steps \u001b[38;5;241m=\u001b[39m [step\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m recipe\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m---> 18\u001b[0m         all_words\u001b[38;5;241m.\u001b[39mextend(tokenize_to_words(step))\n\u001b[0;32m     20\u001b[0m unique_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(all_words)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mКоличество уникальных слов:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(unique_words))\n",
            "Cell \u001b[1;32mIn[10], line 6\u001b[0m, in \u001b[0;36mtokenize_to_words\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_to_words\u001b[39m(s):\n\u001b[1;32m----> 6\u001b[0m     words \u001b[38;5;241m=\u001b[39m word_tokenize(s\u001b[38;5;241m.\u001b[39mlower())\n\u001b[0;32m      7\u001b[0m     words \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39misalpha()] \u001b[38;5;66;03m# Только алфавитные слова\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m words\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m     ]\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers/punkt/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:750\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m _open(resource_url)\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, path \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
            "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\kiril/nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def tokenize_to_words(s):\n",
        "    words = word_tokenize(s.lower())\n",
        "    words = [word for word in words if word.isalpha()] # Только алфавитные слова\n",
        "    return words\n",
        "\n",
        "\n",
        "tree = ET.parse(\"steps_sample.xml\")\n",
        "root = tree.getroot()\n",
        "\n",
        "all_words = []\n",
        "for recipe in root.findall('recipe'):\n",
        "    steps = [step.text.strip() for step in recipe.find('steps').findall('step')]\n",
        "    for step in steps:\n",
        "        all_words.extend(tokenize_to_words(step))\n",
        "\n",
        "unique_words = set(all_words)\n",
        "\n",
        "print(\"Количество уникальных слов:\", len(unique_words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeGJ4WGQRnVz"
      },
      "source": [
        "7\\. Разбейте описания рецептов из `recipes` на предложения при помощи пакета `nltk`. Найдите 5 самых длинных описаний (по количеству _предложений_) рецептов в датасете и выведите строки фрейма, соответствующие этим рецептами, в порядке убывания длины."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REum_EVORnVz",
        "outputId": "2bbaaebe-7540-4a62-b9e9-410e1bdfa535"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\kiril\\anaconda3\\lib\\site-packages (3.8.1)\n",
            "Requirement already satisfied: click in c:\\users\\kiril\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
            "Requirement already satisfied: joblib in c:\\users\\kiril\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kiril\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
            "Requirement already satisfied: tqdm in c:\\users\\kiril\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\kiril\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJNQw8okRnVz",
        "outputId": "28261cf7-a79e-4fe2-d115-5fefcb65f399"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\kiril/nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m recipes \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecipes_sample.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Разбиение всех значений в столбце description на их предложения, преобразование в их количество и получение пяти записей с наибольшими значеняими\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m longest \u001b[38;5;241m=\u001b[39m recipes\u001b[38;5;241m.\u001b[39mloc[recipes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m))][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(tokenize_to_sentences)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# print(longest)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, num_sentences \u001b[38;5;129;01min\u001b[39;00m longest\u001b[38;5;241m.\u001b[39mitems():\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
            "Cell \u001b[1;32mIn[15], line 6\u001b[0m, in \u001b[0;36mtokenize_to_sentences\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_to_sentences\u001b[39m(text):\n\u001b[1;32m----> 6\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m sent_tokenize(text)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentences\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers/punkt/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:750\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m _open(resource_url)\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, path \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
            "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\kiril/nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kiril\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "def tokenize_to_sentences(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    return sentences\n",
        "\n",
        "\n",
        "recipes = pd.read_csv('recipes_sample.csv', header=0)\n",
        "\n",
        "# Разбиение всех значений в столбце description на их предложения, преобразование в их количество и получение пяти записей с наибольшими значеняими\n",
        "longest = recipes.loc[recipes['description'].apply(lambda x: isinstance(x, str))]['description'].apply(tokenize_to_sentences).apply(len).nlargest(5)\n",
        "# print(longest)\n",
        "\n",
        "for idx, num_sentences in longest.items():\n",
        "    description = recipes.iloc[idx]['description']\n",
        "    print(f\"---------------------------------------------------------------------------\"\n",
        "          f\"\\nРецепт #{idx} ({num_sentences} предложений):\\n{description}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhz4dZ-kRnV0"
      },
      "source": [
        "8\\. Напишите функцию, которая для заданного предложения выводит информацию о частях речи слов, входящих в предложение, в следующем виде:\n",
        "```\n",
        "PRP   VBD   DT      NNS     CC   VBD      NNS        RB   \n",
        " I  omitted the raspberries and added strawberries instead\n",
        "```\n",
        "Для определения части речи слова можно воспользоваться `nltk.pos_tag`.\n",
        "\n",
        "Проверьте работоспособность функции на названии рецепта с id 241106.\n",
        "\n",
        "Обратите внимание, что часть речи должна находиться ровно посередине над соотвествующим словом, а между самими словами должен быть ровно один пробел.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1XOtvRJRnV0"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "def pos_tag_sentence(sentence):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    return pos_tags\n",
        "\n",
        "try:\n",
        "    pos_tag_sentence('')\n",
        "except LookupError:\n",
        "    import nltk\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def process(pos_tags):\n",
        "    output = \"\"\n",
        "    for token, pos_tag in pos_tags:\n",
        "        output += f\"{pos_tag:<5}\"\n",
        "    output += \"\\n\"\n",
        "\n",
        "    for token, _ in pos_tags:\n",
        "        output += f\"{token} \"\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "recipe_id = 241106\n",
        "recipes = pd.read_csv('recipes_sample.csv', header=0)\n",
        "recipe_data = recipes[recipes['id'] == recipe_id]\n",
        "\n",
        "print(process(pos_tag_sentence(recipe_data['name'].values[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc1CNc8aRnV0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}